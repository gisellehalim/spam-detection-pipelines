# Submission 1: Spam Detection Pipeline
Name: Giselle Halim

Dicoding username: gisellehalim

| | Description |
| ----------- | ----------- |
| Dataset | [Spam](https://www.kaggle.com/datasets/matleonard/nlp-course) |
| Problem Statement | With the rapid advancement of technology, more and more messages will be received by users of email or other social media. In addition to messages whose senders are known (such as family or friends), many messages are now sent with a specific purpose. The purpose can be for promotions, newsletters, and even attempted scams. These messages are usually annoying because they are numerous and frequent, which is what is called “spam”. Many recipients of spam messages are annoyed and some are victims of fraudulent spam messages. |
| Machine Learning Solution | With machine learning, a system can be created to filter spam messages that can help reduce the amount of spam that users receive. In addition, if there is a spam message, the user can also be warned to ignore it. |
| Data Preprocessing | To improve the model training process, this dataset is divided into train data and test data with a ratio of 80:20. After that, the text content in the “text” column is changed to lowercase (to make the data more consistent) and change the “label” column to integer (because it is a number). Notes: In the original dataset, the label is not numeric, so I modify the data so that the label has a numeric format (0 = ham/not spam, 1 = spam). The datasets in this folder are the datasets whose labels have been changed. |
| Model Architecture | The model is built with the functional API of TensorFlow. The first layer is the input layer which will be filled with features/text as input. Then there is a vectorize layer which is a layer that functions to convert input to lowercase format and no punctuation, limit the size of the vocabulary to prevent overfitting, convert to integer format (so that the model can process), and limit the input length so that the input size is consistent. Next, an embedding layer with an embedding dimension of 16 is used to learn the meaning and patterns in the text. Then, a GlobalAveragePool1D layer is used to reduce the input dimension, the 1D type is used because the data is in the form of text. After that, there are two Dense layers (64 and 32 units) with relay activation. Finally, a Dense layer for binary classification with sigmoid activation. The loss type binary_crossentropy is used because there are only 2 classes (binary classification), Adam for the optimizer (learning rate 0.01), and the binary accuracy metric score is shown as one of the references in training. |
| Evaluation Metrics | The metrics used in the model are ExampleCount, BinaryAccuracy, TruePositive, FalsePositive, TrueNegative, FalseNegative, and AUC to evaluate the performance of the model in classifying spam or non-spam messages. |
| Model Performance | The evaluation results show that the model performance is very good with an AUC score of 0.99, binary accuracy score of 0.98, example count of 1092, true positive of 135, false positive of 1, true negative of 939, false negative of 17, and loss of 0.08. |
